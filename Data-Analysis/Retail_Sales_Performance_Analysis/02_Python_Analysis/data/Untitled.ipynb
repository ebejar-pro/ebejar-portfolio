{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a447b-3100-4f8e-a876-0622e2c3e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. CONFIGURATION (Run this cell first) ---\n",
    "# Define the file paths for your five CSV files.\n",
    "FILES = {\n",
    "    'sales': 'sales.csv',\n",
    "    'customers': 'customers.csv',\n",
    "    'employees': 'employees.csv',\n",
    "    'products': 'products.csv',\n",
    "    'sales_commission': 'sales_commission.csv'\n",
    "}\n",
    "\n",
    "def load_data(files: dict) -> dict:\n",
    "    \"\"\"Loads all CSV files into a dictionary of pandas DataFrames.\"\"\"\n",
    "    data_frames = {}\n",
    "    print(\"--- 1. Loading DataFrames ---\")\n",
    "    for name, path in files.items():\n",
    "        try:\n",
    "            # We assume sales_date and dispatch_date are present in sales.csv\n",
    "            if name == 'sales':\n",
    "                # Error handling for the case where date columns might not exist yet or are incorrectly formatted\n",
    "                try:\n",
    "                    # Attempt to parse dates for sales.csv\n",
    "                    data_frames[name] = pd.read_csv(path, parse_dates=['sale_date', 'dispatch_date'])\n",
    "                except Exception:\n",
    "                    # Fallback if date parsing fails\n",
    "                    data_frames[name] = pd.read_csv(path)\n",
    "                    print(f\"⚠️ Warning: Could not parse dates automatically for {name}. Data types need verification.\")\n",
    "            else:\n",
    "                data_frames[name] = pd.read_csv(path)\n",
    "            print(f\"✅ Loaded {name}: {len(data_frames[name]):,} rows.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ ERROR: File not found at path: {path}\")\n",
    "            return None # Exit if critical file is missing\n",
    "    return data_frames\n",
    "\n",
    "def clean_and_inspect_data(dfs: dict):\n",
    "    \"\"\"Checks for nulls, duplicates, and verifies data types.\"\"\"\n",
    "    print(\"\\n--- 2. Data Cleaning and Inspection ---\")\n",
    "    for name, df in dfs.items():\n",
    "        print(f\"\\n[Table: {name}]\")\n",
    "        \n",
    "        # Check for Nulls\n",
    "        null_count = df.isnull().sum().sum()\n",
    "        if null_count > 0:\n",
    "            print(f\"⚠️ Warning: Found {null_count} total null values.\")\n",
    "        else:\n",
    "            print(\"✅ No null values found.\")\n",
    "\n",
    "        # Check for Duplicates\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        if duplicate_count > 0:\n",
    "            print(f\"⚠️ Warning: Found {duplicate_count} duplicate rows. Dropping them.\")\n",
    "            dfs[name] = df.drop_duplicates()\n",
    "        else:\n",
    "            print(\"✅ No exact duplicate rows found.\")\n",
    "        \n",
    "        # Display Data Types\n",
    "        print(\"Data Types:\")\n",
    "        print(df.dtypes)\n",
    "        \n",
    "        # CRITICAL INSPECTION: Print column names to confirm structure\n",
    "        if name == 'products':\n",
    "             print(\"\\n!!! CRITICAL CHECK: PRODUCTS COLUMNS FOUND !!!\")\n",
    "             print(df.columns.tolist())\n",
    "\n",
    "\n",
    "def merge_data(dfs: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges all relevant tables into a single master analysis DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 3. Merging DataFrames (Star Schema Join) ---\")\n",
    "\n",
    "    # --- FIX FOR MISSING 'CATEGORY' COLUMN ---\n",
    "    # Since 'category' is missing, we add a placeholder column to the products DataFrame\n",
    "    # so downstream analysis (like grouping) can still proceed without KeyError.\n",
    "    if 'category' not in dfs['products'].columns:\n",
    "        dfs['products']['category'] = 'Uncategorized'\n",
    "        print(\"⚠️ WARNING: 'category' column was missing in products.csv. Added 'Uncategorized' placeholder column to proceed.\")\n",
    "    # --- END FIX ---\n",
    "    \n",
    "    # 1. Merge Sales (Fact) with Products (Dimensions)\n",
    "    # Now we can safely select 'category' (which is now guaranteed to exist)\n",
    "    master_df = dfs['sales'].merge(\n",
    "        dfs['products'][['product_id', 'product_name', 'price', 'cost_price', 'category']],\n",
    "        on='product_id',\n",
    "        how='left',\n",
    "        suffixes=('_sales', '_product')\n",
    "    )\n",
    "\n",
    "    # 2. Merge with Employees\n",
    "    master_df = master_df.merge(\n",
    "        dfs['employees'][['employee_id', 'name', 'department']],\n",
    "        on='employee_id',\n",
    "        how='left'\n",
    "    ).rename(columns={'name': 'employee_name'}) \n",
    "\n",
    "    # 3. Merge with Customers\n",
    "    master_df = master_df.merge(\n",
    "        dfs['customers'][['customer_id', 'first_name', 'last_name', 'age', 'city']],\n",
    "        on='customer_id',\n",
    "        how='left'\n",
    "    ).rename(columns={'first_name': 'customer_first_name', 'last_name': 'customer_last_name'})\n",
    "    \n",
    "    print(f\"✅ Final Master DataFrame created with {len(master_df):,} rows.\")\n",
    "    return master_df\n",
    "\n",
    "def feature_engineer_financials(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Creates core financial columns (Revenue, COGS, Profit, Fulfillment Days).\"\"\"\n",
    "    print(\"\\n--- 4. Feature Engineering: Financial Metrics ---\")\n",
    "    \n",
    "    # Calculate Total Revenue for each sale row\n",
    "    df['Revenue'] = df['quantity'] * df['price']\n",
    "    \n",
    "    # Calculate Total Cost of Goods Sold (COGS)\n",
    "    df['COGS'] = df['quantity'] * df['cost_price']\n",
    "    \n",
    "    # Calculate Total Profit (Gross Margin)\n",
    "    df['Profit'] = df['Revenue'] - df['COGS']\n",
    "    \n",
    "    # Calculate the Fulfillment Latency\n",
    "    df['Fulfillment_Days'] = (df['dispatch_date'] - df['sale_date']).dt.days\n",
    "\n",
    "    print(\"✅ New columns created: Revenue, COGS, Profit, Fulfillment_Days.\")\n",
    "    \n",
    "    # Display quick summary of new columns\n",
    "    print(\"\\nQuick Financial Summary:\")\n",
    "    print(f\"Total Revenue: ${df['Revenue'].sum():,.2f}\")\n",
    "    print(f\"Total Profit: ${df['Profit'].sum():,.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- 5. EXECUTION BLOCK (Run this cell last) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Load all data\n",
    "    dfs = load_data(FILES)\n",
    "\n",
    "    if dfs:\n",
    "        # Inspect and clean \n",
    "        clean_and_inspect_data(dfs)\n",
    "\n",
    "        # Merge into a single analysis table\n",
    "        master_df = merge_data(dfs)\n",
    "\n",
    "        # Create financial calculation columns\n",
    "        final_df = feature_engineer_financials(master_df)\n",
    "\n",
    "        # Display the first few rows of the final dataset\n",
    "        print(\"\\n--- 5. Final Master Data Preview ---\")\n",
    "        # Note: 'sale_name' column was likely a typo in the original prompt, replacing with 'product_name' for safety\n",
    "        print(final_df[['sale_id', 'sale_date', 'employee_name', 'product_name', 'category', 'Revenue', 'Profit', 'Fulfillment_Days']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
