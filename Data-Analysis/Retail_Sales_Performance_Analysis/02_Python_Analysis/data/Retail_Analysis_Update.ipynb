{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8a447b-3100-4f8e-a876-0622e2c3e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LOGGING COMPLETE ---\n",
      "All output has been saved to: retail_analysis_log.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys # Added for logging redirection\n",
    "import datetime # Added for timestamping the log\n",
    "\n",
    "# --- 1. CONFIGURATION (Run this cell first) ---\n",
    "FILES = {\n",
    "    'sales': 'sales.csv',\n",
    "    'customers': 'customers.csv',\n",
    "    'employees': 'employees.csv',\n",
    "    'products': 'products.csv',\n",
    "    'sales_commission': 'sales_commission.csv'\n",
    "}\n",
    "\n",
    "def load_data(files: dict) -> dict:\n",
    "    \"\"\"Loads all CSV files into a dictionary of pandas DataFrames.\"\"\"\n",
    "    data_frames = {}\n",
    "    print(\"--- 1. Loading DataFrames ---\")\n",
    "    for name, path in files.items():\n",
    "        try:\n",
    "            if name == 'sales':\n",
    "                try:\n",
    "                    data_frames[name] = pd.read_csv(path, parse_dates=['sale_date', 'dispatch_date'])\n",
    "                except Exception:\n",
    "                    data_frames[name] = pd.read_csv(path)\n",
    "                    print(f\"⚠️ Warning: Could not parse dates automatically for {name}. Data types need verification.\")\n",
    "            else:\n",
    "                data_frames[name] = pd.read_csv(path)\n",
    "            print(f\"✅ Loaded {name}: {len(data_frames[name]):,} rows.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ ERROR: File not found at path: {path}\")\n",
    "            return None \n",
    "    return data_frames\n",
    "\n",
    "def clean_and_inspect_data(dfs: dict):\n",
    "    \"\"\"Checks for nulls, duplicates, and verifies data types.\"\"\"\n",
    "    print(\"\\n--- 2. Data Cleaning and Inspection ---\")\n",
    "    for name, df in dfs.items():\n",
    "        print(f\"\\n[Table: {name}]\")\n",
    "        \n",
    "        # Check for Nulls\n",
    "        null_count = df.isnull().sum().sum()\n",
    "        if null_count > 0:\n",
    "            print(f\"⚠️ Warning: Found {null_count} total null values.\")\n",
    "        else:\n",
    "            print(\"✅ No null values found.\")\n",
    "\n",
    "        # Check for Duplicates\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        if duplicate_count > 0:\n",
    "            print(f\"⚠️ Warning: Found {duplicate_count} duplicate rows. Dropping them.\")\n",
    "            dfs[name] = df.drop_duplicates()\n",
    "        else:\n",
    "            print(\"✅ No exact duplicate rows found.\")\n",
    "        \n",
    "        # Display Data Types\n",
    "        print(\"Data Types:\")\n",
    "        print(df.dtypes)\n",
    "        \n",
    "        # CRITICAL INSPECTION: Print column names\n",
    "        if name == 'products':\n",
    "             print(\"\\n!!! CHECK: PRODUCTS COLUMNS !!!\")\n",
    "             print(df.columns.tolist())\n",
    "        if name == 'employees':\n",
    "             print(\"\\n!!! CHECK: EMPLOYEES COLUMNS !!!\")\n",
    "             print(df.columns.tolist())\n",
    "        if name == 'customers':\n",
    "             print(\"\\n!!! CHECK: CUSTOMERS COLUMNS !!!\")\n",
    "             print(df.columns.tolist())\n",
    "\n",
    "\n",
    "def merge_data(dfs: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges all relevant tables into a single master analysis DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 3. Merging DataFrames (Star Schema Join) ---\")\n",
    "\n",
    "    # 1. Merge Sales (Fact) with Products (Dimensions)\n",
    "    # We rely on your updated CSV having the 'category' column now.\n",
    "    master_df = dfs['sales'].merge(\n",
    "        dfs['products'][['product_id', 'product_name', 'price', 'cost_price', 'category']],\n",
    "        on='product_id',\n",
    "        how='left',\n",
    "        suffixes=('_sales', '_product')\n",
    "    )\n",
    "\n",
    "    # 2. Merge with Employees\n",
    "    # Correctly using 'job_code' instead of 'department'\n",
    "    master_df = master_df.merge(\n",
    "        dfs['employees'][['employee_id', 'name', 'job_code']], \n",
    "        on='employee_id',\n",
    "        how='left'\n",
    "    ).rename(columns={'name': 'employee_name'}) \n",
    "\n",
    "    # 3. Merge with Customers\n",
    "    # FIX: Corrected to use 'name' instead of 'first_name'/'last_name' and removed 'city' \n",
    "    # based on user feedback about the actual CSV structure.\n",
    "    master_df = master_df.merge(\n",
    "        dfs['customers'][['customer_id', 'name', 'age']],\n",
    "        on='customer_id',\n",
    "        how='left'\n",
    "    ).rename(columns={'name': 'customer_name'}) # Rename 'name' column for clarity\n",
    "    \n",
    "    print(f\"✅ Final Master DataFrame created with {len(master_df):,} rows.\")\n",
    "    return master_df\n",
    "\n",
    "def feature_engineer_financials(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Creates core financial columns (Revenue, COGS, Profit, Fulfillment Days).\"\"\"\n",
    "    print(\"\\n--- 4. Feature Engineering: Financial Metrics ---\")\n",
    "    \n",
    "    # Calculate Total Revenue for each sale row\n",
    "    df['Revenue'] = df['quantity'] * df['price']\n",
    "    \n",
    "    # Calculate Total Cost of Goods Sold (COGS)\n",
    "    df['COGS'] = df['quantity'] * df['cost_price']\n",
    "    \n",
    "    # Calculate Total Profit (Gross Margin)\n",
    "    df['Profit'] = df['Revenue'] - df['COGS']\n",
    "    \n",
    "    # Calculate the Fulfillment Latency\n",
    "    df['Fulfillment_Days'] = (df['dispatch_date'] - df['sale_date']).dt.days\n",
    "\n",
    "    print(\"✅ New columns created: Revenue, COGS, Profit, Fulfillment_Days.\")\n",
    "    \n",
    "    # Display quick summary of new columns\n",
    "    print(\"\\nQuick Financial Summary:\")\n",
    "    print(f\"Total Revenue: ${df['Revenue'].sum():,.2f}\")\n",
    "    print(f\"Total Profit: ${df['Profit'].sum():,.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- 5. EXECUTION BLOCK (Run this cell last) ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Define the log file path\n",
    "    log_file_path = \"retail_analysis_log.txt\"\n",
    "    original_stdout = sys.stdout # Save the original stdout\n",
    "\n",
    "    try:\n",
    "        # 1. Redirect all print output to the log file\n",
    "        with open(log_file_path, 'w', encoding='utf-8') as f:\n",
    "            sys.stdout = f # Change the standard output to the file stream\n",
    "            \n",
    "            print(f\"--- RETAIL ANALYSIS LOG STARTED: {datetime.datetime.now()} ---\")\n",
    "            \n",
    "            # Load all data\n",
    "            dfs = load_data(FILES)\n",
    "\n",
    "            if dfs:\n",
    "                # Inspect and clean \n",
    "                clean_and_inspect_data(dfs)\n",
    "\n",
    "                # Merge into a single analysis table\n",
    "                master_df = merge_data(dfs)\n",
    "\n",
    "                # Create financial calculation columns\n",
    "                final_df = feature_engineer_financials(master_df)\n",
    "\n",
    "                # Display the first few rows of the final dataset\n",
    "                print(\"\\n--- 5. Final Master Data Preview (First 5 Rows) ---\")\n",
    "                # Ensure the DataFrame is converted to string for logging\n",
    "                print(final_df[['sale_id', 'sale_date', 'customer_name', 'age', 'employee_name', 'job_code', 'product_name', 'category', 'Revenue']].head().to_string())\n",
    "            \n",
    "            print(f\"\\n--- RETAIL ANALYSIS LOG FINISHED: {datetime.datetime.now()} ---\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Print errors to the console (original stdout) even if logging failed\n",
    "        sys.stdout = original_stdout\n",
    "        print(f\"An error occurred during execution: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        # 2. Reset stdout to the original value (the Jupyter cell output)\n",
    "        sys.stdout = original_stdout\n",
    "        print(f\"\\n--- LOGGING COMPLETE ---\")\n",
    "        print(f\"All output has been saved to: {log_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510400ee",
   "metadata": {},
   "source": [
    "1. Data Preparation and Integrity Check\n",
    "\n",
    "This initial phase focuses on establishing a clean, unified, and financially enriched dataset from five separate CSV sources, ensuring the foundation for subsequent business analysis is robust and accurate.\n",
    "\n",
    "Objective\n",
    "\n",
    "To perform Data Ingestion, Cleaning, ETL (Extract, Transform, Load) logic validation, and Dimensional Modeling (Star Schema) creation using Python (Pandas), confirming all data is merged correctly and key financial metrics are accurately calculated.\n",
    "\n",
    "Execution Summary\n",
    "\n",
    "The script successfully loaded all five source files, performed critical column checks, and merged them into a single master_df (Fact Table), enriching it with necessary financial features.\n",
    "\n",
    "Table\n",
    "\n",
    "Rows Loaded\n",
    "\n",
    "Status\n",
    "\n",
    "sales\n",
    "\n",
    "201\n",
    "\n",
    "Loaded & Date Parsed\n",
    "\n",
    "customers\n",
    "\n",
    "47\n",
    "\n",
    "Loaded\n",
    "\n",
    "employees\n",
    "\n",
    "11\n",
    "\n",
    "Loaded\n",
    "\n",
    "products\n",
    "\n",
    "13\n",
    "\n",
    "Loaded\n",
    "\n",
    "sales_commission\n",
    "\n",
    "197\n",
    "\n",
    "Loaded\n",
    "\n",
    "Data Integrity and Modeling Validation\n",
    "\n",
    "Schema Alignment: Corrected dynamic schema inconsistencies during the merge process, successfully mapping single name columns in customers and employees (renamed to customer_name and employee_name) and utilizing the corrected job_code field from the employees table.\n",
    "\n",
    "Category Integration: Verified the presence and use of the category column in the products table, ensuring products are correctly segmented for future analysis.\n",
    "\n",
    "No Data Loss: The master DataFrame contains 201 rows, matching the total record count of the core sales table, confirming a complete LEFT JOIN (Star Schema) without record duplication or loss.\n",
    "\n",
    "Data Quality: All source tables passed validation checks for null values and duplicate records, confirming high initial data quality.\n",
    "\n",
    "Feature Engineering & Financial Reconciliation\n",
    "\n",
    "Key financial metrics were engineered successfully, serving as the basis for performance reporting:\n",
    "\n",
    "Metric\n",
    "\n",
    "Calculation\n",
    "\n",
    "Reconciled Value\n",
    "\n",
    "Total Revenue\n",
    "\n",
    "quantity * price\n",
    "\n",
    "$387,496.20\n",
    "\n",
    "Total COGS\n",
    "\n",
    "quantity * cost_price\n",
    "\n",
    "(Calculated internally)\n",
    "\n",
    "Total Profit\n",
    "\n",
    "Revenue - COGS\n",
    "\n",
    "$158,284.70\n",
    "\n",
    "Fulfillment Days\n",
    "\n",
    "dispatch_date - sale_date\n",
    "\n",
    "(Calculated internally)\n",
    "\n",
    "Reconciliation Note: The calculated Total Revenue and Total Profit figures have been reconciled against expected results derived from independent SQL queries, confirming the accuracy of the Python feature engineering logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7067c65-7b4c-41d8-b76f-353559da996f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
